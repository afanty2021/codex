# 核心端点

<cite>
**本文档中引用的文件**   
- [chat.rs](file://codex-rs/codex-api/src/endpoint/chat.rs)
- [compact.rs](file://codex-rs/codex-api/src/endpoint/compact.rs)
- [models.rs](file://codex-rs/codex-api/src/endpoint/models.rs)
- [chat.rs](file://codex-rs/codex-api/src/requests/chat.rs)
- [responses.rs](file://codex-rs/codex-api/src/requests/responses.rs)
- [common.rs](file://codex-rs/codex-api/src/common.rs)
- [responses.rs](file://codex-rs/codex-api/src/endpoint/responses.rs)
</cite>

## 目录
1. [介绍](#介绍)
2. [/chat 端点](#chat-端点)
3. [/compact 端点](#compact-端点)
4. [/models 端点](#models-端点)
5. [请求体结构](#请求体结构)
6. [响应结构](#响应结构)
7. [调用示例](#调用示例)

## 介绍
本文档详细描述了Codex内部API的核心RESTful端点，包括`/chat`、`/compact`和`/models`端点的实现细节。文档涵盖了每个端点的HTTP方法、完整URL路径、请求参数（路径、查询、请求体）和响应格式，并提供了使用`curl`和Rust `reqwest`客户端调用这些端点的具体示例。

## /chat 端点

`/chat`端点用于处理聊天完成请求，支持流式响应。该端点根据配置的wire API使用不同的路径。

- **HTTP方法**: POST
- **URL路径**: 
  - 当wire API为`Chat`时: `/chat/completions`
  - 当wire API为`Responses`时: `/responses`
- **请求头**: 
  - `Authorization: Bearer <token>`
  - `ChatGPT-Account-ID: <account_id>`
  - `Accept: text/event-stream`
  - `conversation_id: <conversation_id>` (可选)
  - `session_id: <session_id>` (可选)
  - `x-openai-subagent: <subagent_type>` (可选)

**Section sources**
- [chat.rs](file://codex-rs/codex-api/src/endpoint/chat.rs#L70-L75)
- [chat.rs](file://codex-rs/codex-api/src/endpoint/chat.rs#L77-L85)

## /compact 端点

`/compact`端点用于压缩对话历史，仅支持`Responses`或`Compact`类型的wire API。

- **HTTP方法**: POST
- **URL路径**: `/responses/compact`
- **请求头**: 
  - `Authorization: Bearer <token>`
  - `ChatGPT-Account-ID: <account_id>`
- **错误情况**: 当wire API为`Chat`时，会返回错误"compact endpoint requires responses wire api"

**Section sources**
- [compact.rs](file://codex-rs/codex-api/src/endpoint/compact.rs#L39-L45)
- [compact.rs](file://codex-rs/codex-api/src/endpoint/compact.rs#L48-L71)

## /models 端点

`/models`端点用于列出可用的AI模型及其元数据。

- **HTTP方法**: GET
- **URL路径**: `/models`
- **查询参数**: `client_version=<version>` (客户端版本)
- **请求头**: 
  - `Authorization: Bearer <token>`
  - `ChatGPT-Account-ID: <account_id>`
- **响应头**: 包含`ETag`头，用于缓存验证

**Section sources**
- [models.rs](file://codex-rs/codex-api/src/endpoint/models.rs#L36-L38)
- [models.rs](file://codex-rs/codex-api/src/endpoint/models.rs#L40-L80)

## 请求体结构

### Chat请求体
`/chat`端点的请求体包含以下字段：

- **model** (字符串): 使用的模型名称
- **messages** (数组): 对话消息列表，每个消息包含:
  - `role` (字符串): 角色 ("system", "user", "assistant", "tool")
  - `content` (字符串或对象数组): 消息内容
  - `tool_calls` (数组): 工具调用信息
  - `reasoning` (字符串): 推理内容
- **stream** (布尔值): 是否启用流式响应 (始终为true)
- **tools** (数组): 可用工具定义
- **tool_choice** (字符串): 工具选择策略

### Responses请求体
`/responses`端点的请求体结构与Chat类似，但包含额外字段：

- **reasoning** (对象): 推理配置
  - `effort` (字符串): 推理努力程度
  - `summary` (对象): 推理摘要配置
- **store** (布尔值): 是否存储对话状态
- **include** (数组): 包含的响应项
- **prompt_cache_key** (字符串): 提示缓存键
- **text** (对象): 文本控制
  - `verbosity` (字符串): 详细程度 ("low", "medium", "high")
  - `format` (对象): 输出格式

**Section sources**
- [chat.rs](file://codex-rs/codex-api/src/requests/chat.rs#L312-L317)
- [responses.rs](file://codex-rs/codex-api/src/requests/responses.rs#L113-L126)
- [common.rs](file://codex-rs/codex-api/src/common.rs#L120-L136)

## 响应结构

### 成功响应
成功响应采用SSE (Server-Sent Events) 格式，包含以下事件类型：

- **Created**: 响应创建事件
- **OutputItemDone**: 输出项完成事件，包含:
  - `type` (字符串): 项类型 ("message", "function_call", "reasoning"等)
  - `role` (字符串): 角色
  - `content` (数组): 内容项
- **OutputTextDelta**: 文本增量事件，包含新生成的文本片段
- **ReasoningContentDelta**: 推理内容增量事件
- **Completed**: 响应完成事件，包含:
  - `response_id` (字符串): 响应ID
  - `token_usage` (对象): 令牌使用情况

### 错误响应
错误响应可能包含以下类型：

- **ApiError**: API错误，包含状态码和消息
- **StreamError**: 流式传输错误
- **TransportError**: 传输层错误
- **RateLimitError**: 速率限制错误
- **ContextWindowExceeded**: 上下文窗口超出错误
- **QuotaExceeded**: 配额超出错误

**Section sources**
- [common.rs](file://codex-rs/codex-api/src/common.rs#L40-L62)
- [error.rs](file://codex-rs/codex-api/src/error.rs#L7-L35)
- [responses.rs](file://codex-rs/codex-api/src/sse/responses.rs#L564-L587)

## 调用示例

### 使用curl调用/chat端点
```bash
curl -X POST https://api.example.com/v1/chat/completions \
  -H "Authorization: Bearer your-api-token" \
  -H "Content-Type: application/json" \
  -H "Accept: text/event-stream" \
  -d '{
    "model": "gpt-4",
    "messages": [
      {"role": "system", "content": "You are a helpful assistant"},
      {"role": "user", "content": "Hello!"}
    ],
    "stream": true
  }'
```

### 使用Rust reqwest客户端调用/models端点
```rust
use reqwest;
use serde_json::Value;

async fn list_models() -> Result<Value, Box<dyn std::error::Error>> {
    let client = reqwest::Client::new();
    let response = client
        .get("https://api.example.com/v1/models")
        .header("Authorization", "Bearer your-api-token")
        .query(&[("client_version", "1.0.0")])
        .send()
        .await?;
    
    let models: Value = response.json().await?;
    Ok(models)
}
```

### 使用Rust客户端调用/chat端点
```rust
use codex_api::{ChatClient, Provider, NoAuth};
use codex_client::ReqwestTransport;
use serde_json::json;

async fn chat_completion() -> Result<(), Box<dyn std::error::Error>> {
    let transport = ReqwestTransport::new(reqwest::Client::new());
    let provider = Provider {
        name: "openai".to_string(),
        base_url: "https://api.openai.com/v1".to_string(),
        wire: WireApi::Chat,
        // ... 其他配置
    };
    
    let client = ChatClient::new(transport, provider, NoAuth);
    let request_body = json!({
        "model": "gpt-4",
        "messages": [
            {"role": "user", "content": "Hello!"}
        ],
        "stream": true
    });
    
    let stream = client.stream(request_body, HeaderMap::new()).await?;
    // 处理流式响应
    Ok(())
}
```

**Section sources**
- [clients.rs](file://codex-rs/codex-api/tests/clients.rs#L197-L208)
- [clients.rs](file://codex-rs/codex-api/tests/clients.rs#L211-L223)
- [clients.rs](file://codex-rs/codex-api/tests/clients.rs#L225-L237)